[è·³è‡³å†…å®¹](https://chatgpt.com/c/688210b9-c480-8008-b9fe-6217a4ed1172#main)

## å†å²èŠå¤©è®°å½•









##### æ‚¨è¯´ï¼š

""" çº¿æ€§å›å½’ç›´æ¥é¢„æµ‹æˆ¿å­ä»·æ ¼ :return: None """ # è·å–æ•°æ® fe_cal = fetch_california_housing(data_home='data') print("è·å–ç‰¹å¾å€¼") print(fe_cal.data.shape) print('-' * 50) print(fe_cal.data[0]) print("ç›®æ ‡å€¼") print(fe_cal.target) #å•ä½æ˜¯10ä¸‡ç¾é‡‘ print(fe_cal.DESCR) print('-' * 50) print(fe_cal.feature_names) #ç‰¹å¾åˆ—çš„åå­—.ä»£ç ä½œç”¨

###### ChatGPT è¯´ï¼š

è¿™æ®µä»£ç æ˜¯ç”¨æ¥**è·å–å¹¶æŸ¥çœ‹åŠ åˆ©ç¦å°¼äºšæˆ¿ä»·æ•°æ®é›†**ï¼ˆCalifornia Housing datasetï¼‰ï¼Œä¸ºåç»­çš„**çº¿æ€§å›å½’å»ºæ¨¡é¢„æµ‹æˆ¿ä»·**åšå‡†å¤‡ã€‚ä¸‹é¢æ˜¯é€è¡Œè§£é‡ŠåŠå…¶ä½œç”¨ï¼š

------

### ğŸ”§ æ‰€éœ€æ¨¡å—

```
from sklearn.datasets import fetch_california_housing
```

- `fetch_california_housing` æ˜¯ `sklearn.datasets` ä¸­çš„ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºä¸‹è½½å’ŒåŠ è½½åŠ å·æˆ¿ä»·æ•°æ®é›†ï¼ˆCalifornia Housing datasetï¼‰ã€‚

------

### ğŸ  åŠ è½½æ•°æ®

```
fe_cal = fetch_california_housing(data_home='data')
```

- åŠ è½½åŠ å·æˆ¿ä»·æ•°æ®é›†ã€‚
- `data_home='data'` æŒ‡å®šå°†æ•°æ®ä¸‹è½½å¹¶ç¼“å­˜åˆ°æœ¬åœ° `data` ç›®å½•ã€‚
- è¿”å›çš„æ˜¯ä¸€ä¸ª **`Bunch`** ç±»å‹ï¼ˆç±»ä¼¼å­—å…¸ï¼‰ï¼ŒåŒ…å«äº†ç‰¹å¾å€¼ã€ç›®æ ‡å€¼ã€ç‰¹å¾åã€æè¿°ä¿¡æ¯ç­‰ã€‚

------

### ğŸ“Š æ‰“å°ç‰¹å¾å€¼å½¢çŠ¶

```
print("è·å–ç‰¹å¾å€¼")
print(fe_cal.data.shape)
```

- `.data` æ˜¯æ•°æ®é›†ä¸­çš„ç‰¹å¾çŸ©é˜µï¼Œç±»å‹ä¸º `numpy.ndarray`ã€‚
- `.shape` è¿”å›çš„æ˜¯ (æ ·æœ¬æ•°, ç‰¹å¾æ•°)ï¼Œæ¯”å¦‚ `(20640, 8)` è¡¨ç¤ºå…±æœ‰ 20640 ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬æœ‰ 8 ä¸ªç‰¹å¾ã€‚

------

### ğŸ” æ‰“å°é¦–è¡Œç‰¹å¾æ•°æ®

```
print('-' * 50)
print(fe_cal.data[0])
```

- æ‰“å°ç¬¬ä¸€ä¸ªæ ·æœ¬çš„æ‰€æœ‰ç‰¹å¾å€¼ï¼ˆ8 ä¸ª float æ•°å€¼ï¼‰ã€‚

------

### ğŸ¯ æ‰“å°ç›®æ ‡å€¼ï¼ˆæˆ¿ä»·ï¼‰

```
print("ç›®æ ‡å€¼")
print(fe_cal.target) #å•ä½æ˜¯10ä¸‡ç¾é‡‘
```

- `.target` æ˜¯æ¯ä¸ªæ ·æœ¬å¯¹åº”çš„æˆ¿ä»·ç›®æ ‡å€¼ï¼ˆå•ä½ï¼š10ä¸‡ç¾å…ƒï¼‰ã€‚
- æ˜¯ä¸€ä¸ªä¸€ç»´æ•°ç»„ï¼Œå½¢å¦‚ `[4.526, 3.585, 3.521, ...]`ã€‚

------

### ğŸ“˜ æ•°æ®é›†è¯´æ˜æ–‡æ¡£

```
print(fe_cal.DESCR)
```

- `.DESCR` æ˜¯è¯¥æ•°æ®é›†çš„æ–‡å­—æè¿°ï¼ŒåŒ…æ‹¬æ¥æºã€å„ç‰¹å¾çš„å«ä¹‰ã€ä½¿ç”¨å»ºè®®ç­‰ã€‚

------

### ğŸ·ï¸ ç‰¹å¾åç§°

```
print('-' * 50)
print(fe_cal.feature_names)
```

- `.feature_names` æ˜¯ä¸€ä¸ªåŒ…å« 8 ä¸ªå­—ç¬¦ä¸²çš„åˆ—è¡¨ï¼Œå¯¹åº”æ¯åˆ—ç‰¹å¾çš„åç§°ï¼š

```
['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms',
 'Population', 'AveOccup', 'Latitude', 'Longitude']
```

| ç‰¹å¾å     | å«ä¹‰                 |
| ---------- | -------------------- |
| MedInc     | åŒºåŸŸä½æˆ·æ”¶å…¥ä¸­ä½æ•°   |
| HouseAge   | æˆ¿å±‹å¹³å‡å»ºé€ å¹´é™     |
| AveRooms   | æ¯ä¸ªå®¶åº­çš„å¹³å‡æˆ¿é—´æ•° |
| AveBedrms  | æ¯ä¸ªå®¶åº­çš„å¹³å‡å§å®¤æ•° |
| Population | åŒºåŸŸäººå£             |
| AveOccup   | æ¯æˆ·å¹³å‡äººæ•°         |
| Latitude   | çº¬åº¦                 |
| Longitude  | ç»åº¦                 |

------

### âœ… æ€»ç»“ï¼šä»£ç çš„ä½œç”¨

è¿™æ®µä»£ç çš„ä¸»è¦ä½œç”¨æ˜¯ï¼š

- ä¸‹è½½å¹¶åŠ è½½åŠ å·æˆ¿ä»·æ•°æ®é›†ï¼›
- è¾“å‡ºç‰¹å¾çŸ©é˜µçš„å½¢çŠ¶ã€é¦–è¡Œæ•°æ®ã€ç›®æ ‡å€¼ã€ç‰¹å¾ååŠæ•°æ®æè¿°ï¼›
- ä¸ºåç»­æ„å»ºå¦‚çº¿æ€§å›å½’æ¨¡å‹ç­‰æœºå™¨å­¦ä¹ ä»»åŠ¡æä¾›æ•°æ®åŸºç¡€ã€‚

å¦‚æœä½ åç»­è¦ç”¨ `LinearRegression` æ¥é¢„æµ‹æˆ¿ä»·ï¼Œè¿™æ®µä»£ç å°±ä½œä¸ºæ•°æ®åŠ è½½å’Œæ¢ç´¢çš„ç¬¬ä¸€æ­¥ã€‚

------

å¦‚éœ€ç»§ç»­ï¼Œæˆ‘å¯ä»¥å¸®ä½ å†™å‡º **çº¿æ€§å›å½’å»ºæ¨¡ã€è®­ç»ƒã€è¯„ä¼°ä¸å¯è§†åŒ–å®Œæ•´æµç¨‹**ï¼Œæ˜¯å¦éœ€è¦ï¼Ÿ

##### æ‚¨è¯´ï¼š

ä»¥ä¸‹ä»£ç ä½œç”¨æ˜¯ä»€ä¹ˆï¼šfe_cal.target.shape #%% # åˆ†å‰²æ•°æ®é›†åˆ°è®­ç»ƒé›†å’Œæµ‹è¯•é›† x_train, x_test, y_train, y_test = train_test_split(fe_cal.data, fe_cal.target, test_size=0.25, random_state=1) # print(x_train.shape) # # # è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†(?) ç›®æ ‡å€¼å¤„ç†ï¼Ÿ # # ç‰¹å¾å€¼å’Œç›®æ ‡å€¼æ˜¯éƒ½å¿…é¡»è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†, å®ä¾‹åŒ–ä¸¤ä¸ªæ ‡å‡†åŒ–API std_x = StandardScaler() # x_train = std_x.fit_transform(x_train) #è®­ç»ƒé›†æ ‡å‡†åŒ– x_test = std_x.transform(x_test) #æµ‹è¯•é›†æ ‡å‡†åŒ– # ç›®æ ‡å€¼è¿›è¡Œäº†æ ‡å‡†åŒ–ï¼Œæš‚æ—¶æ²¡æœ‰å¯¹ç›®æ ‡å€¼è¿›è¡Œæ ‡å‡†åŒ–å¤„ç† # std_y = StandardScaler() # # temp = y_train.reshape(-1, 1) #-1ä»£è¡¨æŠŠå‰©ä½™çš„å…ƒç´ éƒ½å †åˆ°å“ªä¸€ç»´ # # #æ ‡ç­¾ï¼ˆç›®æ ‡ï¼‰è¿›è¡Œæ ‡å‡†åŒ– # # ç›®æ ‡å€¼æ˜¯ä¸€ç»´çš„ï¼Œè¿™é‡Œéœ€è¦ä¼ è¿›å»2ç»´çš„ # y_train = std_y.fit_transform(y_train.reshape(-1, 1))  #æŠŠä¸€ç»´çš„æ ‡ç­¾å˜æˆäºŒç»´çš„ # print(y_train.shape) # y_test = std_y.transform(y_test.reshape(-1, 1)) # print(y_test.shape) #%% test1=np.array([1,2,3]) print(test1.shape) test1.reshape(-1,1).shape #%% import os # # estimatoré¢„æµ‹ # # # æ­£è§„æ–¹ç¨‹æ±‚è§£æ–¹å¼é¢„æµ‹ç»“æœï¼Œæ­£è§„æ–¹ç¨‹è¿›è¡Œçº¿æ€§å›å½’ lr = LinearRegression() # fitæ˜¯è€—æ—¶çš„ lr.fit(x_train, y_train) #å›å½’ç³»æ•°å¯ä»¥çœ‹ç‰¹å¾ä¸ç›®æ ‡ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œç³»æ•°è¶Šå¤§ï¼Œç›¸å…³æ€§è¶Šå¼ºï¼Œè´Ÿç›¸å…³æ„å‘³ç€ç‰¹å¾ä¸ç›®æ ‡çš„æ–¹å‘ç›¸å print('å›å½’ç³»æ•°', lr.coef_) # y_predict = lr.predict(x_test) # é¢„æµ‹æµ‹è¯•é›†çš„æˆ¿å­ä»·æ ¼ï¼Œé€šè¿‡inverseå¾—åˆ°çœŸæ­£çš„æˆ¿å­ä»·æ ¼ # y_lr_predict = std_y.inverse_transform(y_predict) # ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œæ¨¡å‹ä¸­ä¿å­˜çš„æ˜¯wçš„å€¼ï¼Œä¹Ÿä¿å­˜äº†æ¨¡å‹ç»“æ„ #ä¿å­˜æ¨¡å‹æ”¾åœ¨fitä¹‹åå³å¯ os.unlink('./tmp/test.pkl') # åˆ é™¤ä¹‹å‰çš„æ¨¡å‹æ–‡ä»¶ joblib.dump(lr, "./tmp/test.pkl")  # ä¿å­˜æ¨¡å‹ print("æ­£è§„æ–¹ç¨‹æµ‹è¯•é›†é‡Œé¢æ¯ä¸ªæˆ¿å­çš„é¢„æµ‹ä»·æ ¼ï¼š", y_predict[0:10]) #ä¸‹é¢æ˜¯æ±‚æµ‹è¯•é›†çš„æŸå¤±ï¼Œç”¨å‡æ–¹è¯¯å·®ï¼Œå…¬å¼æ˜¯(y_test-y_predict)^2/n print("æ­£è§„æ–¹ç¨‹çš„å‡æ–¹è¯¯å·®ï¼š", mean_squared_error(y_test, y_predict)) #%% #æ­£è§„æ–¹ç¨‹çš„å‡æ–¹è¯¯å·®ï¼š 0.535653284542256 #%% md # 2 åŠ è½½ä¿å­˜çš„æ¨¡å‹ #%% #æ¨¡æ‹Ÿä¸Šçº¿æ—¶åŠ è½½æ¨¡å‹ model = joblib.load("./tmp/test.pkl") # # å› ä¸ºç›®æ ‡å€¼è¿›è¡Œäº†æ ‡å‡†åŒ–ï¼Œä¸€å®šè¦æŠŠé¢„æµ‹åçš„å€¼é€†å‘è½¬æ¢å›æ¥ y_predict = model.predict(x_test) # print("ä¿å­˜çš„æ¨¡å‹é¢„æµ‹çš„ç»“æœï¼š", y_predict) print("æ­£è§„æ–¹ç¨‹çš„å‡æ–¹è¯¯å·®ï¼š", mean_squared_error(y_test, y_predict)) # print("æ­£è§„æ–¹ç¨‹inverseåçš„å‡æ–¹è¯¯å·®ï¼š", mean_squared_error(std_y.inverse_transform(y_test), #                                                std_y.inverse_transform(y_predict))) #%% y_true = [3, -0.5, 2, 7] y_pred = [2.5, 0.0, 2, 8] mean_squared_error(y_true, y_pred) #%% #äººå·¥æ±‚å‡æ–¹è¯¯å·® (np.square(3 - 2.5) + np.square(0.5) + 1) / 4 #%% md # 3 çº¿æ€§å›å½’ä¹‹æ¢¯åº¦ä¸‹é™å»è¿›è¡Œæˆ¿ä»·é¢„æµ‹ #%% # æ¢¯åº¦ä¸‹é™å»è¿›è¡Œæˆ¿ä»·é¢„æµ‹,æ•°æ®é‡å¤§è¦ç”¨è¿™ä¸ª # learning_rateçš„ä¸åŒæ–¹å¼ï¼Œä»£è¡¨å­¦ä¹ ç‡å˜åŒ–çš„ç®—æ³•ä¸ä¸€æ ·,æ¯”å¦‚constant,invscaling,adaptive # é»˜è®¤å¯ä»¥å»è°ƒ eta0 = 0.008ï¼Œä¼šæ”¹å˜learning_rateçš„åˆå§‹å€¼ # learning_rate='optimal',alphaæ˜¯æ­£åˆ™åŒ–åŠ›åº¦ï¼Œä½†æ˜¯ä¼šå½±å“å­¦ä¹ ç‡çš„å€¼ï¼Œç”±alphaæ¥ç®—å­¦ä¹ ç‡ # penaltyä»£è¡¨æ­£åˆ™åŒ–ï¼Œåˆ†ä¸ºl1å’Œl2 # eta0=0.01, penalty='l2',max_iter=1000 sgd = SGDRegressor(eta0=0.01,penalty='l2', max_iter=1000) # # è®­ç»ƒ sgd.fit(x_train, y_train) # print('æ¢¯åº¦ä¸‹é™çš„å›å½’ç³»æ•°', sgd.coef_) # # é¢„æµ‹æµ‹è¯•é›†çš„æˆ¿å­ä»·æ ¼ # y_sgd_predict = std_y.inverse_transform(sgd.predict(x_test).reshape(-1, 1)) y_predict = sgd.predict(x_test) # print("æ¢¯åº¦ä¸‹é™æµ‹è¯•é›†é‡Œé¢æ¯ä¸ªæˆ¿å­çš„é¢„æµ‹ä»·æ ¼ï¼š", y_sgd_predict) print("æ¢¯åº¦ä¸‹é™çš„å‡æ–¹è¯¯å·®ï¼š", mean_squared_error(y_test, y_predict)) # print("æ¢¯åº¦ä¸‹é™çš„åŸå§‹æˆ¿ä»·é‡çº²å‡æ–¹è¯¯å·®ï¼š", mean_squared_error(std_y.inverse_transform(y_test), y_sgd_predict)) #%% w=1 lreaning_rate=0.1  #å­¦ä¹ ç‡ def loss(w):    return 2*w**2+3*w+2 def dao_shu(w):    return 4*w+3 for i in range(30):    w=w-lreaning_rate*dao_shu(w)    print(f'w {w} æŸå¤±{loss(w)}') #%% md # 4 å²­å›å½’ #%% # # # å²­å›å½’å»è¿›è¡Œæˆ¿ä»·é¢„æµ‹ #å²­å›å½’æ˜¯å¯¹çº¿æ€§å›å½’åŠ å…¥L2æ­£åˆ™åŒ–ï¼ŒL2æ­£åˆ™åŒ–æ˜¯å¯¹ç³»æ•°çš„å¹³æ–¹å’Œè¿›è¡Œæƒ©ç½š #alphaå°±æ˜¯è¡¥å¿çš„ç³»æ•° #æ­£è§„æ–¹ç¨‹æ±‚è§£ï¼ŒåŠ è¡¥å¿å°±å¯ä»¥è®©æ­£è§„æ–¹ç¨‹å¯é€† rd = Ridge(alpha=0.02) rd.fit(x_train, y_train) print(rd.coef_) # # # é¢„æµ‹æµ‹è¯•é›†çš„æˆ¿å­ä»·æ ¼ print(rd.predict(x_test).shape) # y_rd_predict = std_y.inverse_transform(rd.predict(x_test)) y_predict = rd.predict(x_test) # print("å²­å›å½’é‡Œé¢æ¯ä¸ªæˆ¿å­çš„é¢„æµ‹ä»·æ ¼ï¼š", y_rd_predict) print("å²­å›å½’çš„å‡æ–¹è¯¯å·®ï¼š", mean_squared_error(y_test, y_predict)) # print("å²­å›å½’çš„å‡æ–¹è¯¯å·®ï¼š", mean_squared_error(std_y.inverse_transform(y_test), y_rd_predict)) #%% md # 5 lassoå›å½’ #%% # # # Lassoå›å½’å»è¿›è¡Œæˆ¿ä»·é¢„æµ‹ #alphaå°±æ˜¯è¡¥å¿çš„ç³»æ•° print(x_train.shape) print(y_train.shape) ls = Lasso(alpha=0.001) ls.fit(x_train, y_train) print(ls.coef_) # # # é¢„æµ‹æµ‹è¯•é›†çš„æˆ¿å­ä»·æ ¼ print(ls.predict(x_test).shape) print('-'*50) # y_ls_predict = std_y.inverse_transform(ls.predict(x_test).reshape(-1,1)) y_predict = ls.predict(x_test) # print("Lassoå›å½’é‡Œé¢æ¯ä¸ªæˆ¿å­çš„é¢„æµ‹ä»·æ ¼ï¼š", y_rd_predict) # print("Lassoå›å½’çš„å‡æ–¹è¯¯å·®ï¼š", mean_squared_error(y_test, y_predict)) # print("Lassoå›å½’çš„å‡æ–¹è¯¯å·®ï¼š", mean_squared_error(std_y.inverse_transform(y_test), y_ls_predict)) #%% md # 6 é€»è¾‘å›å½’ å¯ä»¥åšåˆ†ç±»é—®é¢˜ï¼Œé¢„æµ‹ç™Œç—‡æ˜¯å¦è‰¯æ€§ï¼Œé¢„æµ‹è‚¡ç¥¨æ¶¨è·Œï¼Œé¢„æµ‹ç—…äººæ˜¯å¦ä¼šæ­»äº¡ç­‰ç­‰ #%% np.log(0.5) #%% np.log(0.3) #%% x=np.arange(0.001,1,0.01) #0-1ä¹‹é—´ï¼Œæ­¥é•¿0.01 import matplotlib.pyplot as plt plt.plot(x,-np.log(x))  #ä»¥eä¸ºåº•éƒ¨ plt.show() #%% x=np.arange(0,1,0.01) import matplotlib.pyplot as plt plt.plot(x,-np.log(1-x)) plt.show() #%% """ é€»è¾‘å›å½’åšäºŒåˆ†ç±»è¿›è¡Œç™Œç—‡é¢„æµ‹ï¼ˆæ ¹æ®ç»†èƒçš„å±æ€§ç‰¹å¾ï¼‰ :return: NOne """ # æ„é€ åˆ—æ ‡ç­¾åå­— column = ['Sample code number', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape',          'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli',          'Mitoses', 'Class'] # è¯»å–æ•°æ® # data = pd.read_csv( #     "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data", #     names=column) data = pd.read_csv(    "./data/breast-cancer-wisconsin.csv",    names=column) # print(data) #æƒ³çœ‹å¯ä»¥è§£é™¤ #å½“ä½ è¯»å–æ•°æ®æ—¶ï¼Œçœ‹ä¸Šå»æ˜¯æ•°å€¼çš„åˆ—ï¼Œè¯»è¿›æ¥æ˜¯å­—ç¬¦ä¸²ï¼Œè¯´æ˜é‡Œè¾¹ # å­˜åœ¨äº†éæ•°å€¼æƒ…å†µ print(data.info()) print(data.describe(include='all')) #%% data['Bare Nuclei'].unique() #å› ä¸ºä¸Šé¢å‘ç°å®ƒæ˜¯objectç±»å‹ #%% # ç¼ºå¤±å€¼è¿›è¡Œå¤„ç† data = data.replace(to_replace='?', value=np.nan) #ç›´æ¥åˆ é™¤ï¼Œå“ªä¸€è¡Œæœ‰ç©ºå€¼ï¼Œå°±åˆ é™¤å¯¹åº”çš„æ ·æœ¬ data = data.dropna() print('-' * 50) print(data.shape) #%% data.info() #%% column[10] #%% #åˆ†ç±»çš„ç±»åˆ«æ˜¯2å’Œ4,å¯¹åº” "è‰¯æ€§", "æ¶æ€§" data[column[10]].unique() #%% data.info() #%% column[6] #%% #æŠŠç¬¬6åˆ—çš„å­—ç¬¦ä¸²è½¬åŒ–ä¸ºæ•°å­—ç±»å‹ data[column[6]] = data[column[6]].astype('int16') #%% data.info() #%% # è¿›è¡Œæ•°æ®çš„åˆ†å‰²,ç¬¬é›¶åˆ—æ˜¯ç¼–å·ï¼Œä¸å¯ä»¥ä½œä¸ºç‰¹å¾ï¼ŒæŠŠç¬¬1-9åˆ—ä½œä¸ºç‰¹å¾ï¼Œç¬¬10åˆ—ä½œä¸ºæ ‡ç­¾ x_train, x_test, y_train, y_test = train_test_split(data[column[1:10]], data[column[10]], test_size=0.25,                                                    random_state=1) # è¿›è¡Œæ ‡å‡†åŒ–å¤„ç† std = StandardScaler() x_train = std.fit_transform(x_train) #è®­ç»ƒé›†æ ‡å‡†åŒ– x_test = std.transform(x_test) #æµ‹è¯•é›†æ ‡å‡†åŒ– x_train[0] #%% # # # é€»è¾‘å›å½’é¢„æµ‹ # Cæ­£åˆ™åŒ–åŠ›åº¦ # solver = 'liblinear'  solveræ˜¯å­¦ä¹ ç‡ä¼˜åŒ–ç®—æ³•ï¼Œå°±æ˜¯å­¦ä¹ ç‡ä¼šéšç€epochçš„å˜åŒ–è€Œå˜åŒ– #epochå°±ä»£è¡¨ç¬¬å‡ æ¬¡è¿­ä»£ #max_iter æœ€å¤§è¿­ä»£æ¬¡æ•° lg = LogisticRegression(C=0.5, solver='lbfgs') # lg.fit(x_train, y_train) # é€»è¾‘å›å½’çš„æƒé‡å‚æ•°ï¼Œäº†è§£ï¼Œæ²¡é‚£ä¹ˆé‡è¦ print(lg.coef_) y_predict = lg.predict(x_test) print(y_predict) #é¢„æµ‹çš„æ ‡ç­¾ print("å‡†ç¡®ç‡ï¼š", lg.score(x_test, y_test)) print(y_test[0:5]) print('-'*50) print(lg.predict_proba(x_test)[0:5])  #å¾—å‡ºå¯¹åº”åˆ†ç±»çš„æ¦‚ç‡ #%% # ä¸ºä»€ä¹ˆè¿˜è¦çœ‹ä¸‹å¬å›ç‡ï¼Œlabelså’Œtarget_nameså¯¹åº” # macro avg å¹³å‡å€¼  weighted avg åŠ æƒå¹³å‡å€¼ print(classification_report(y_test, y_predict, labels=[2, 4], target_names=["è‰¯æ€§", "æ¶æ€§"])) #AUCè®¡ç®—è¦æ±‚æ˜¯äºŒåˆ†ç±»ï¼Œä¸éœ€è¦æ˜¯0å’Œ1 print("AUCæŒ‡æ ‡ï¼š", roc_auc_score(y_test, y_predict)) #%% print(x_train.shape) print(x_test.shape) #%% print(-np.log(0.1)) #%% -np.log(0.9)  #%% x=-3/10 y=5*x**2+3*x+4 y #%%

###### ChatGPT è¯´ï¼š

å·²æ›´æ–°ä¿å­˜çš„è®°å¿†

è¿™æ®µä»£ç æ˜¯ä¸€ä¸ªå®Œæ•´çš„æœºå™¨å­¦ä¹ å»ºæ¨¡æµç¨‹ï¼Œæ¶µç›–äº†ï¼š

1. **æˆ¿ä»·é¢„æµ‹ï¼ˆå›å½’ä»»åŠ¡ï¼‰**ï¼š
   - ä½¿ç”¨äº†çº¿æ€§å›å½’ï¼ˆæ­£è§„æ–¹ç¨‹ï¼‰ã€æ¢¯åº¦ä¸‹é™ã€å²­å›å½’ã€Lassoå›å½’ï¼›
   - ç›®æ ‡æ˜¯ä½¿ç”¨åŠ å·æˆ¿ä»·æ•°æ®é›†é¢„æµ‹æˆ¿å±‹ä»·æ ¼ï¼›
   - ä½¿ç”¨ `mean_squared_error` ä½œä¸ºæ¨¡å‹è¯„ä¼°æ ‡å‡†ï¼›
   - ä½¿ç”¨äº† `StandardScaler` è¿›è¡Œç‰¹å¾æ ‡å‡†åŒ–ï¼›
   - ç”¨ `joblib` å¯¹æ¨¡å‹è¿›è¡Œä¿å­˜ä¸åŠ è½½ï¼›
   - åŒ…å«äº†å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰äººå·¥æ¨å¯¼è¿‡ç¨‹ã€‚
2. **ç™Œç—‡é¢„æµ‹ï¼ˆåˆ†ç±»ä»»åŠ¡ï¼‰**ï¼š
   - ä½¿ç”¨äº†é€»è¾‘å›å½’ï¼›
   - æ•°æ®ä¸ºä¹³è…ºç™Œæ•°æ®é›†ï¼ˆæ¥è‡ªUCIï¼‰ï¼›
   - å¯¹â€œæ˜¯å¦ä¸ºæ¶æ€§è‚¿ç˜¤â€è¿›è¡Œåˆ†ç±»ï¼›
   - ä½¿ç”¨äº† `accuracy`ã€`precision`ã€`recall`ã€`f1-score`ã€`AUC` ç­‰è¯„ä»·æŒ‡æ ‡ã€‚

------

ä¸‹é¢å¯¹å…³é”®ä»£ç å’ŒçŸ¥è¯†ç‚¹é€å—è§£é‡Šï¼š

------

## ğŸ” `fe_cal.target.shape` çš„ä½œç”¨

```
fe_cal.target.shape
```

è¿™æ˜¯ä¸ºäº†æŸ¥çœ‹ç›®æ ‡å€¼ `y` çš„å½¢çŠ¶ï¼ˆç»´åº¦ï¼‰ï¼š

- è¾“å‡ºï¼šå¦‚ `(20640,)`ï¼Œè¡¨ç¤ºå…±æœ‰ 20640 ä¸ªç›®æ ‡å€¼ï¼ˆæˆ¿ä»·æ•°æ®ï¼‰ï¼Œæ˜¯ä¸€ç»´æ•°ç»„ã€‚
- å¦‚æœéœ€è¦å¯¹ç›®æ ‡å€¼è¿›è¡Œæ ‡å‡†åŒ–ï¼Œéœ€ `.reshape(-1, 1)` è½¬æˆäºŒç»´æ•°ç»„ã€‚

------

## ğŸ§ª æ•°æ®åˆ’åˆ†ä¸æ ‡å‡†åŒ–

```
x_train, x_test, y_train, y_test = train_test_split(...)
```

- å°†æ•°æ®åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼›
- `test_size=0.25` è¡¨ç¤ºæµ‹è¯•é›†å  25%ã€‚

```
std_x = StandardScaler()
x_train = std_x.fit_transform(x_train)
x_test = std_x.transform(x_test)
```

- ä½¿ç”¨ `StandardScaler` å¯¹ç‰¹å¾è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ï¼›
- ç›®çš„æ˜¯è®©ç‰¹å¾å€¼æœä»æ ‡å‡†æ­£æ€åˆ†å¸ƒï¼Œæœ‰åˆ©äºæ¢¯åº¦ä¸‹é™ç®—æ³•æ”¶æ•›ã€‚

> âœ… æ³¨æ„ï¼šä½ æ²¡æœ‰å¯¹ç›®æ ‡å€¼ `y` è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ï¼Œä½†æ³¨é‡Šé‡Œè¯´æ˜äº†å¦‚ä½•åšï¼ˆå¦‚ reshape, fit_transformï¼‰ã€‚

------

## ğŸ§® æ¨¡å‹1ï¼šæ­£è§„æ–¹ç¨‹çº¿æ€§å›å½’

```
lr = LinearRegression()
lr.fit(x_train, y_train)
y_predict = lr.predict(x_test)
```

- ä½¿ç”¨ `LinearRegression` å»ºæ¨¡ï¼ˆæ­£è§„æ–¹ç¨‹æ³•ï¼‰ï¼›
- è®­ç»ƒåå¯ä»¥è¾“å‡º `coef_` å›å½’ç³»æ•°ã€‚

```
mean_squared_error(y_test, y_predict)
```

- è®¡ç®—é¢„æµ‹ç»“æœä¸å®é™…æˆ¿ä»·çš„ **å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰**ã€‚

------

## ğŸ’¾ æ¨¡å‹ä¿å­˜ä¸åŠ è½½

```
joblib.dump(lr, "./tmp/test.pkl")
model = joblib.load("./tmp/test.pkl")
```

- ç”¨ `joblib` å°†è®­ç»ƒå¥½çš„æ¨¡å‹ä¿å­˜å¹¶å†æ¬¡åŠ è½½ï¼ˆæ¨¡æ‹Ÿä¸Šçº¿éƒ¨ç½²ï¼‰ï¼›

------

## ğŸ§® æ¨¡å‹2ï¼šæ¢¯åº¦ä¸‹é™çº¿æ€§å›å½’

```
sgd = SGDRegressor(...)
sgd.fit(x_train, y_train)
y_predict = sgd.predict(x_test)
```

- ä½¿ç”¨ `SGDRegressor`ï¼ˆéšæœºæ¢¯åº¦ä¸‹é™æ³•ï¼‰ï¼›
- å­¦ä¹ ç‡ `eta0=0.01`ï¼›
- æ­£åˆ™åŒ–é¡¹ `penalty='l2'` è¡¨ç¤º L2 æ­£åˆ™ã€‚

------

## ğŸ“‰ æ¢¯åº¦ä¸‹é™æ¼”ç¤ºï¼ˆè‡ªå®šä¹‰ä¾‹å­ï¼‰

```
def loss(w): ...
def dao_shu(w): ...
```

- æ¼”ç¤ºæ¢¯åº¦ä¸‹é™ä¼˜åŒ–è¿‡ç¨‹ï¼›
- ç”¨ä¸€ä¸ªç®€å•çš„äºŒæ¬¡å‡½æ•° L(w)=2w2+3w+2*L*(*w*)=2*w*2+3*w*+2ï¼›
- æ¯æ­¥æ ¹æ®å¯¼æ•° dLdw=4w+3*d**w**d**L*=4*w*+3 è¿­ä»£æ›´æ–° `w`ã€‚

------

## ğŸ§® æ¨¡å‹3ï¼šå²­å›å½’ï¼ˆL2æ­£åˆ™ï¼‰

```
rd = Ridge(alpha=0.02)
rd.fit(x_train, y_train)
```

- å²­å›å½’æ˜¯åœ¨çº¿æ€§å›å½’ä¸­åŠ å…¥äº† L2 æ­£åˆ™åŒ–ï¼›
- å¯é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œå°¤å…¶åœ¨ç‰¹å¾å…±çº¿æ€§æ˜æ˜¾æ—¶æ•ˆæœå¥½ã€‚

------

## ğŸ§® æ¨¡å‹4ï¼šLassoå›å½’ï¼ˆL1æ­£åˆ™ï¼‰

```
ls = Lasso(alpha=0.001)
ls.fit(x_train, y_train)
```

- Lasso æ˜¯åŠ å…¥äº† L1 æ­£åˆ™åŒ–çš„çº¿æ€§å›å½’ï¼›
- å¯ä»¥äº§ç”Ÿç¨€ç–è§£ï¼ˆå³éƒ¨åˆ†ç‰¹å¾çš„ç³»æ•°ä¸º 0ï¼Œè‡ªåŠ¨ç‰¹å¾é€‰æ‹©ï¼‰ã€‚

------

## ğŸ§ª æ¨¡å‹5ï¼šé€»è¾‘å›å½’è¿›è¡Œåˆ†ç±»ï¼ˆç™Œç—‡é¢„æµ‹ï¼‰

- åŠ è½½æ•°æ®é›† `breast-cancer-wisconsin`ï¼›
- åˆ é™¤ç¼ºå¤±å€¼ï¼›
- å°†ç‰¹å¾æ ‡å‡†åŒ–ï¼›
- ä½¿ç”¨é€»è¾‘å›å½’ `LogisticRegression` è¿›è¡ŒäºŒåˆ†ç±»ï¼›
- ä½¿ç”¨ `.score()` è®¡ç®—å‡†ç¡®ç‡ï¼›
- ä½¿ç”¨ `classification_report` å’Œ `roc_auc_score` è¿›ä¸€æ­¥è¯„ä»·æ¨¡å‹ï¼š

```
print(classification_report(y_test, y_predict, labels=[2, 4], target_names=["è‰¯æ€§", "æ¶æ€§"]))
print("AUCæŒ‡æ ‡ï¼š", roc_auc_score(y_test, y_predict))
```

------

## ğŸ“ˆ å¯¹æ•°å‡½æ•°å¯è§†åŒ–éƒ¨åˆ†ï¼š

```
x = np.arange(0.001, 1, 0.01)
plt.plot(x, -np.log(x))
```

- å±•ç¤ºäº†é€»è¾‘å›å½’ä¸­çš„å¯¹æ•°æŸå¤±å‡½æ•°çš„å½¢çŠ¶ï¼›
- å¯¹åˆ†ç±»æ¨¡å‹çš„è§£é‡Šï¼ˆå¦‚ log lossï¼‰æœ‰å¸®åŠ©ã€‚

------

## âœ… æ€»ç»“

è¿™æ®µä»£ç ç³»ç»Ÿåœ°å±•ç¤ºäº†ï¼š

| ç±»å‹ | æ¨¡å‹               | æè¿°               |
| ---- | ------------------ | ------------------ |
| å›å½’ | LinearRegression   | æ­£è§„æ–¹ç¨‹           |
| å›å½’ | SGDRegressor       | æ¢¯åº¦ä¸‹é™           |
| å›å½’ | Ridge              | å²­å›å½’ï¼ˆL2ï¼‰       |
| å›å½’ | Lasso              | L1å›å½’             |
| åˆ†ç±» | LogisticRegression | äºŒåˆ†ç±»é¢„æµ‹ï¼ˆç™Œç—‡ï¼‰ |

ä½ å·²ç»æŒæ¡äº†å›å½’ä¸åˆ†ç±»ä¸¤å¤§ç±»æ¨¡å‹çš„ä½¿ç”¨ï¼ŒåŒ…æ‹¬æ¨¡å‹ä¿å­˜ã€æ ‡å‡†åŒ–å¤„ç†ã€è¯¯å·®è®¡ç®—ç­‰ï¼Œä¸‹ä¸€æ­¥å¯ä»¥è¿›ä¸€æ­¥ï¼š

- è¿›è¡Œ **äº¤å‰éªŒè¯** å’Œ **ç½‘æ ¼æœç´¢è°ƒå‚**ï¼›
- ä½¿ç”¨ `Pipeline` ç®¡ç†æ•°æ®æµï¼›
- å°è¯•é›†æˆæ¨¡å‹ï¼ˆå¦‚ `RandomForest`, `GradientBoosting`ï¼‰ç­‰ã€‚

éœ€è¦æˆ‘å¸®ä½ æ‰©å±•æˆä¸€ä¸ªç³»ç»Ÿæ€§é¡¹ç›®æµç¨‹/æŠ¥å‘Šæ¨¡æ¿å—ï¼Ÿæˆ–è€…ä½ æƒ³å°è¯•ç½‘æ ¼æœç´¢è°ƒå‚ã€ç‰¹å¾å·¥ç¨‹ç­‰å†…å®¹ï¼Ÿ

##### æ‚¨è¯´ï¼š

é€è¡Œä»£ç æ³¨é‡Š

###### ChatGPT è¯´ï¼š

ä»¥ä¸‹æ˜¯ä½ ç»™å‡ºçš„ **æˆ¿ä»·é¢„æµ‹ä¸é€»è¾‘å›å½’åˆ†ç±»ä»£ç çš„é€è¡Œè¯¦ç»†æ³¨é‡Š**ï¼Œæ¶µç›–äº†æ•°æ®åŠ è½½ã€é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒã€é¢„æµ‹ã€ä¿å­˜/åŠ è½½ã€å¯è§†åŒ–ä¸è¯„ä»·ç­‰å®Œæ•´è¿‡ç¨‹ã€‚æŒ‰ä»£ç ç»“æ„åˆ†æ®µæ•´ç†ï¼Œæ–¹ä¾¿ä½ å­¦ä¹ ä¸å¤ç›˜ï¼š

------

## ğŸš©**1. è·å–åŠ å·æˆ¿ä»·æ•°æ®é›†**

```
fe_cal = fetch_california_housing(data_home='data')  # ä¸‹è½½åŠ å·æˆ¿ä»·æ•°æ®å¹¶ç¼“å­˜åˆ°æœ¬åœ° data ç›®å½•
print("è·å–ç‰¹å¾å€¼")
print(fe_cal.data.shape)  # æ‰“å°ç‰¹å¾çŸ©é˜µçš„ç»´åº¦ï¼ˆæ ·æœ¬æ•° Ã— ç‰¹å¾æ•°ï¼‰
print('-' * 50)
print(fe_cal.data[0])     # æ‰“å°ç¬¬ä¸€ä¸ªæ ·æœ¬çš„æ‰€æœ‰ç‰¹å¾å€¼
print("ç›®æ ‡å€¼")
print(fe_cal.target)      # æ‰“å°ç›®æ ‡å€¼ï¼ˆæ¯ä¸ªæ ·æœ¬å¯¹åº”çš„æˆ¿ä»·ï¼Œå•ä½ï¼š10ä¸‡ç¾å…ƒï¼‰
print(fe_cal.DESCR)       # æ‰“å°æ•°æ®é›†çš„è¯¦ç»†æè¿°ï¼ˆæ•°æ®æ¥æºã€å­—æ®µå«ä¹‰ç­‰ï¼‰
print('-' * 50)
print(fe_cal.feature_names)  # æ‰“å°ç‰¹å¾ååˆ—è¡¨ï¼Œå¦‚ ['MedInc', 'HouseAge', ...]
fe_cal.target.shape  # æŸ¥çœ‹ç›®æ ‡å€¼ï¼ˆyï¼‰çš„ shapeï¼Œç»“æœä¸º (20640,) è¡¨ç¤ºæ˜¯ä¸€ç»´æ•°ç»„
```

------

## âœ‚ï¸ **2. åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†**

```
x_train, x_test, y_train, y_test = train_test_split(
    fe_cal.data, fe_cal.target, test_size=0.25, random_state=1
)  # æŒ‰ 75% / 25% åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
print(x_train.shape)  # æ‰“å°è®­ç»ƒç‰¹å¾é›†çš„ç»´åº¦
```

------

## ğŸ”§ **3. ç‰¹å¾å€¼æ ‡å‡†åŒ–å¤„ç†**

```
std_x = StandardScaler()  # å®ä¾‹åŒ–ç‰¹å¾æ ‡å‡†åŒ–å™¨
x_train = std_x.fit_transform(x_train)  # å¯¹è®­ç»ƒç‰¹å¾åšæ ‡å‡†åŒ–ï¼šå‡å€¼ä¸º0ã€æ–¹å·®ä¸º1
x_test = std_x.transform(x_test)        # æµ‹è¯•é›†ä¹Ÿè¦ç”¨è®­ç»ƒé›†çš„æ ‡å‡†è¿›è¡Œè½¬æ¢
```

> âœ…ï¼ˆæ³¨ï¼šä½ æ³¨é‡Šäº†ç›®æ ‡å€¼ `y` çš„æ ‡å‡†åŒ–éƒ¨åˆ†ï¼Œå¸¸ç”¨äºå²­å›å½’ã€SGD å›å½’ä¸­ï¼‰

------

## ğŸ§ª **4. è®­ç»ƒçº¿æ€§å›å½’æ¨¡å‹ï¼ˆæ­£è§„æ–¹ç¨‹æ³•ï¼‰**

```
lr = LinearRegression()   # å®ä¾‹åŒ–çº¿æ€§å›å½’æ¨¡å‹
lr.fit(x_train, y_train)  # ç”¨è®­ç»ƒæ•°æ®æ‹Ÿåˆæ¨¡å‹ï¼ˆè®¡ç®—æƒé‡ w å’Œåç½® bï¼‰
print('å›å½’ç³»æ•°', lr.coef_)  # æ‰“å°æ¯ä¸ªç‰¹å¾çš„æƒé‡ç³»æ•°
y_predict = lr.predict(x_test)  # ç”¨æ¨¡å‹å¯¹æµ‹è¯•æ•°æ®è¿›è¡Œé¢„æµ‹ï¼Œå¾—åˆ°é¢„æµ‹æˆ¿ä»·
```

------

## ğŸ’¾ **5. ä¿å­˜å¹¶åŠ è½½æ¨¡å‹**

```
os.unlink('./tmp/test.pkl')  # åˆ é™¤æ—§æ¨¡å‹æ–‡ä»¶ï¼ˆé¿å…å½±å“ï¼‰
joblib.dump(lr, "./tmp/test.pkl")  # ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹åˆ°æœ¬åœ°æ–‡ä»¶
print("æ­£è§„æ–¹ç¨‹æµ‹è¯•é›†é‡Œé¢æ¯ä¸ªæˆ¿å­çš„é¢„æµ‹ä»·æ ¼ï¼š", y_predict[0:10])  # æ˜¾ç¤ºå‰10ä¸ªé¢„æµ‹æˆ¿ä»·
print("æ­£è§„æ–¹ç¨‹çš„å‡æ–¹è¯¯å·®ï¼š", mean_squared_error(y_test, y_predict))  # è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼ˆMSEï¼‰
```

------

## ğŸ“‚ **6. åŠ è½½å·²ä¿å­˜æ¨¡å‹å¹¶è¯„ä¼°**

```
model = joblib.load("./tmp/test.pkl")  # ä»ç£ç›˜åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹
y_predict = model.predict(x_test)      # ç”¨åŠ è½½çš„æ¨¡å‹å†æ¬¡å¯¹æµ‹è¯•æ•°æ®è¿›è¡Œé¢„æµ‹
print("ä¿å­˜çš„æ¨¡å‹é¢„æµ‹çš„ç»“æœï¼š", y_predict)
print("æ­£è§„æ–¹ç¨‹çš„å‡æ–¹è¯¯å·®ï¼š", mean_squared_error(y_test, y_predict))
```

------

## ğŸ”¢ **7. äººå·¥è®¡ç®— MSE**

```
y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0.0, 2, 8]
mean_squared_error(y_true, y_pred)  # sklearn è‡ªå¸¦å‡æ–¹è¯¯å·®è®¡ç®—
(np.square(3 - 2.5) + np.square(0.5) + 1) / 4  # æ‰‹åŠ¨è®¡ç®— MSE = ((0.5)^2 + (0.5)^2 + 0 + 1^2) / 4
```

------

## âš™ï¸ **8. æ¢¯åº¦ä¸‹é™æ¨¡æ‹Ÿæ¼”ç¤º**

```
w = 1
lreaning_rate = 0.1  # å­¦ä¹ ç‡

def loss(w): return 2 * w**2 + 3 * w + 2   # è‡ªå®šä¹‰æŸå¤±å‡½æ•°
def dao_shu(w): return 4 * w + 3           # è‡ªå®šä¹‰å¯¼æ•°å‡½æ•°ï¼ˆæ¢¯åº¦ï¼‰

for i in range(30):
    w = w - lreaning_rate * dao_shu(w)  # æ¢¯åº¦æ›´æ–°å…¬å¼
    print(f'w {w} æŸå¤±{loss(w)}')        # è¾“å‡ºæ¯æ¬¡è¿­ä»£åçš„ w å’ŒæŸå¤±å€¼
```

------

## ğŸ“‰ **9. ä½¿ç”¨ SGDRegressorï¼ˆæ¢¯åº¦ä¸‹é™ï¼‰**

```
sgd = SGDRegressor(eta0=0.01, penalty='l2', max_iter=1000)  # SGD å›å½’å™¨ï¼ŒL2æ­£åˆ™
sgd.fit(x_train, y_train)                                   # è®­ç»ƒæ¨¡å‹
print('æ¢¯åº¦ä¸‹é™çš„å›å½’ç³»æ•°', sgd.coef_)
y_predict = sgd.predict(x_test)                             # é¢„æµ‹
print("æ¢¯åº¦ä¸‹é™çš„å‡æ–¹è¯¯å·®ï¼š", mean_squared_error(y_test, y_predict))
```

------

## ğŸ§Š **10. å²­å›å½’ï¼ˆRidgeï¼šL2æ­£åˆ™ï¼‰**

```
rd = Ridge(alpha=0.02)        # å®ä¾‹åŒ–å²­å›å½’æ¨¡å‹
rd.fit(x_train, y_train)      # è®­ç»ƒæ¨¡å‹
print(rd.coef_)               # æ‰“å°å›å½’ç³»æ•°
y_predict = rd.predict(x_test)
print("å²­å›å½’çš„å‡æ–¹è¯¯å·®ï¼š", mean_squared_error(y_test, y_predict))
```

------

## ğŸ” **11. Lassoå›å½’ï¼ˆL1æ­£åˆ™ï¼‰**

```
ls = Lasso(alpha=0.001)       # å®ä¾‹åŒ– Lasso å›å½’ï¼ˆL1æ­£åˆ™ï¼‰
ls.fit(x_train, y_train)      # è®­ç»ƒæ¨¡å‹
print(ls.coef_)
y_predict = ls.predict(x_test)
print("Lassoå›å½’çš„å‡æ–¹è¯¯å·®ï¼š", mean_squared_error(y_test, y_predict))
```

------

## ğŸ“¦ **12. åŠ è½½ä¹³è…ºç™Œæ•°æ®é›†ï¼ˆé€»è¾‘å›å½’ï¼‰**

```
column = [...]  # å®šä¹‰åˆ—å
data = pd.read_csv("./data/breast-cancer-wisconsin.csv", names=column)
print(data.info())              # æŸ¥çœ‹æ•°æ®ç±»å‹
print(data.describe(include='all'))  # æ•°æ®æ¦‚è§ˆ
data['Bare Nuclei'].unique()   # æŸ¥çœ‹ç‰¹å®šåˆ—æ˜¯å¦æœ‰å¼‚å¸¸å­—ç¬¦
```

------

## ğŸ§¼ **13. ç¼ºå¤±å€¼å¤„ç† + ç±»å‹è½¬æ¢**

```
data = data.replace(to_replace='?', value=np.nan)  # ç”¨ NaN æ›¿æ¢ '?'
data = data.dropna()                               # åˆ é™¤å« NaN çš„è¡Œ
data[column[6]] = data[column[6]].astype('int16')  # ç±»å‹è½¬æ¢ï¼šå­—ç¬¦ä¸² â æ•´æ•°
```

------

## âœ‚ï¸ **14. åˆ’åˆ†è®­ç»ƒé›†ä¸æµ‹è¯•é›† + æ ‡å‡†åŒ–**

```
x_train, x_test, y_train, y_test = train_test_split(
    data[column[1:10]], data[column[10]], test_size=0.25, random_state=1
)
std = StandardScaler()
x_train = std.fit_transform(x_train)
x_test = std.transform(x_test)
```

------

## ğŸ¤– **15. é€»è¾‘å›å½’åˆ†ç±»å™¨**

```
lg = LogisticRegression(C=0.5, solver='lbfgs')  # å®ä¾‹åŒ–é€»è¾‘å›å½’ï¼Œå¸¦æ­£åˆ™é¡¹
lg.fit(x_train, y_train)                        # è®­ç»ƒæ¨¡å‹
print(lg.coef_)             # æ‰“å°æ¨¡å‹ç³»æ•°
y_predict = lg.predict(x_test)  # é¢„æµ‹æ ‡ç­¾
print("å‡†ç¡®ç‡ï¼š", lg.score(x_test, y_test))  # è®¡ç®—å‡†ç¡®ç‡
print(lg.predict_proba(x_test)[0:5])          # è¾“å‡ºé¢„æµ‹ä¸ºæ¯ç±»çš„æ¦‚ç‡
```

------

## ğŸ“Š **16. åˆ†ç±»æ€§èƒ½è¯„ä»·æŒ‡æ ‡**

```
print(classification_report(y_test, y_predict, labels=[2, 4], target_names=["è‰¯æ€§", "æ¶æ€§"]))
print("AUCæŒ‡æ ‡ï¼š", roc_auc_score(y_test, y_predict))  # AUC å€¼è¯„ä»·æ¨¡å‹æ€§èƒ½
```

------

## ğŸ“ˆ **17. å¯¹æ•°å‡½æ•°ç»˜å›¾ï¼ˆæŸå¤±å‡½æ•°åŸç†ï¼‰**

```
x = np.arange(0.001, 1, 0.01)
plt.plot(x, -np.log(x))          # ç”» -log(x) å›¾åƒ
plt.show()

x = np.arange(0, 1, 0.01)
plt.plot(x, -np.log(1 - x))      # ç”» -log(1-x) å›¾åƒ
plt.show()
```

------

## âœ… å°ç»“

ä½ å®ç°äº†ä»æ•°æ®é¢„å¤„ç† â å›å½’é¢„æµ‹ â æ¨¡å‹ä¿å­˜ â æ¨¡å‹è¯„ä¼° â åˆ†ç±»é¢„æµ‹ â æ€§èƒ½è¯„ä¼°çš„å®Œæ•´æµç¨‹ï¼Œæ˜¯æœºå™¨å­¦ä¹ è®­ç»ƒ-é¢„æµ‹æµç¨‹çš„ç»å…¸æ ·æ¿ã€‚

------

å¦‚æœä½ éœ€è¦ï¼Œæˆ‘å¯ä»¥è¿›ä¸€æ­¥ï¼š

- å¸®ä½ ç”Ÿæˆ**æ±‡æŠ¥æ–‡æ¡£ï¼ˆWordã€PDFï¼‰**
- åŠ å…¥**ç½‘æ ¼æœç´¢è°ƒå‚**
- å°†å¤šä¸ªæ¨¡å‹æ•´åˆä¸º**ç»Ÿä¸€ Pipeline**
- ä½¿ç”¨äº¤å‰éªŒè¯ã€å­¦ä¹ æ›²çº¿è¯„ä¼°è¿‡æ‹Ÿåˆ

æ˜¯å¦éœ€è¦æˆ‘ååŠ©ä¸‹ä¸€æ­¥ï¼Ÿ







ChatGPT ä¹Ÿå¯èƒ½ä¼šçŠ¯é”™ã€‚è¯·æ ¸æŸ¥é‡è¦ä¿¡æ¯ã€‚